{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "786df1667a9444ef067bca5d3684fc6f",
     "grade": false,
     "grade_id": "cell-142eb68406c17bde",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Week 12-1 Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c75e9055174abaeaa215aa1eb8b2fb0f",
     "grade": false,
     "grade_id": "cell-b4f848964553845a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Recap\n",
    "\n",
    "Last class we implmented functions called `f_torch` that evaluated $f(x) = 3x^\\intercal x - x_1 - 4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "def f_torch(x):\n",
    "    return 3 * x.dot(x) - x[0] - 4\n",
    "x = torch.tensor(np.arange(10), dtype=torch.float32, requires_grad=True)\n",
    "f_torch(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7ac6b9ee7c51ab4bc3a7bc2e50b0f932",
     "grade": false,
     "grade_id": "cell-5828c2b34ad2d44c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Problem 1: Minimizing our function with gradient descent\n",
    "Write a function that minimizes $f$ using gradient descent, by calling by calling `f_torch`. The function should take two arguments: an initial iterate `x0` and a number of gradient descent iterations `num_iters`. It should return the minimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "step_size=0.1\n",
    "def minimize(x0, num_iters):\n",
    "    x = x0\n",
    "    # YOUR CODE HERE: Iterative gradient-based minimizer.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_opt = minimize(torch.zeros(3, requires_grad=True), 30)\n",
    "assert (x_opt - torch.Tensor([0.1667, 0.0000, 0.0000])).norm() < 1e-3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
